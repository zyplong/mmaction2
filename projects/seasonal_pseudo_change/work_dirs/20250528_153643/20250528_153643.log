2025/05/28 15:36:48 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: win32
    Python: 3.10.16 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:19:12) [MSC v.1929 64 bit (AMD64)]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1011112419
    GPU 0: Quadro P1000
    CUDA_HOME: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8
    NVCC: Cuda compilation tools, release 11.8, V11.8.89
    MSVC: ?? x64 ? Microsoft (R) C/C++ ????? 19.43.34810 ?
    GCC: n/a
    PyTorch: 2.1.0+cu118
    PyTorch compiling details: PyTorch built with:
  - C++ Version: 199711
  - MSVC 192930151
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX512
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /bigobj /FS -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /utf-8 /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=OFF, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.0+cu118
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1011112419
    diff_rank_seed: False
    deterministic: False
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2025/05/28 15:36:49 - mmengine - INFO - Config:
ann_file_train = 'F:/zyp/Thesis source code/mmaction2/projects/seasonal_pseudo_change/datasets/splits/train.txt'
ann_file_val = 'F:/zyp/Thesis source code/mmaction2/projects/seasonal_pseudo_change/datasets/splits/val.txt'
data_prefix = dict(
    img=
    'F:/zyp/Thesis source code/mmaction2/projects/seasonal_pseudo_change/datasets/rawframes'
)
data_root = 'F:/zyp/Thesis source code/mmaction2/projects/seasonal_pseudo_change/datasets/rawframes'
default_hooks = dict(
    checkpoint=dict(
        interval=1, max_keep_ckpts=1, save_best='auto', type='CheckpointHook'),
    logger=dict(ignore_last=False, interval=10, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    runtime_info=dict(type='RuntimeInfoHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    sync_buffers=dict(type='SyncBuffersHook'),
    timer=dict(type='IterTimerHook'))
default_scope = 'mmaction'
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)
model = dict(
    backbone=dict(
        arch='tiny',
        attn_drop_rate=0.0,
        drop_path_rate=0.1,
        drop_rate=0.0,
        mlp_ratio=4.0,
        patch_norm=True,
        patch_size=(
            2,
            4,
            4,
        ),
        pretrained=
        'F:/zyp/Thesis source code/mmaction2/projects/seasonal_pseudo_change/pretrained/videoswin/swin_tiny_patch244_window877_kinetics400_1k_converted.pth',
        pretrained2d=False,
        qk_scale=None,
        qkv_bias=True,
        type='SwinTransformer3D',
        window_size=(
            8,
            7,
            7,
        )),
    cls_head=dict(
        average_clips='prob',
        dropout_ratio=0.5,
        in_channels=768,
        num_classes=2,
        spatial_type='avg',
        type='I3DHead'),
    data_preprocessor=dict(
        format_shape='NCTHW',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='ActionDataPreprocessor'),
    type='Recognizer3D')
optim_wrapper = dict(
    constructor='SwinOptimWrapperConstructor',
    loss_scale='dynamic',
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ), lr=0.001, type='AdamW', weight_decay=0.02),
    paramwise_cfg=dict(
        absolute_pos_embed=dict(decay_mult=0.0),
        backbone=dict(lr_mult=0.1),
        bias=dict(decay_mult=0.0),
        norm=dict(decay_mult=0.0),
        relative_position_bias_table=dict(decay_mult=0.0)),
    type='AmpOptimWrapper')
param_scheduler = [
    dict(
        begin=0,
        by_epoch=True,
        convert_to_iter_based=True,
        end=2.5,
        start_factor=0.1,
        type='LinearLR'),
    dict(
        T_max=30,
        begin=0,
        by_epoch=True,
        end=30,
        eta_min=0,
        type='CosineAnnealingLR'),
]
randomness = dict(deterministic=False, diff_rank_seed=False, seed=None)
resume = False
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=4,
    dataset=dict(
        ann_file=
        'F:/zyp/Thesis source code/mmaction2/projects/seasonal_pseudo_change/datasets/splits/val.txt',
        data_prefix=dict(
            img=
            'F:/zyp/Thesis source code/mmaction2/projects/seasonal_pseudo_change/datasets/rawframes'
        ),
        filename_tmpl='img_{:04d}.jpg',
        pipeline=[
            dict(
                clip_len=8,
                frame_interval=1,
                num_clips=1,
                test_mode=True,
                type='SampleFrames'),
            dict(type='RawFrameDecode'),
            dict(scale=(
                -1,
                256,
            ), type='Resize'),
            dict(crop_size=224, type='CenterCrop'),
            dict(input_format='NCTHW', type='FormatShape'),
            dict(type='PackActionInputs'),
        ],
        test_mode=True,
        type='RawframeDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(type='AccMetric')
train_cfg = dict(
    max_epochs=50, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)
train_dataloader = dict(
    batch_size=4,
    dataset=dict(
        ann_file=
        'F:/zyp/Thesis source code/mmaction2/projects/seasonal_pseudo_change/datasets/splits/train.txt',
        data_prefix=dict(
            img=
            'F:/zyp/Thesis source code/mmaction2/projects/seasonal_pseudo_change/datasets/rawframes'
        ),
        filename_tmpl='img_{:04d}.jpg',
        pipeline=[
            dict(
                clip_len=8, frame_interval=1, num_clips=1,
                type='SampleFrames'),
            dict(type='RawFrameDecode'),
            dict(scale=(
                -1,
                256,
            ), type='Resize'),
            dict(type='RandomResizedCrop'),
            dict(keep_ratio=False, scale=(
                224,
                224,
            ), type='Resize'),
            dict(flip_ratio=0.5, type='Flip'),
            dict(input_format='NCTHW', type='FormatShape'),
            dict(type='PackActionInputs'),
        ],
        type='RawframeDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=4,
    dataset=dict(
        ann_file=
        'F:/zyp/Thesis source code/mmaction2/projects/seasonal_pseudo_change/datasets/splits/val.txt',
        data_prefix=dict(
            img=
            'F:/zyp/Thesis source code/mmaction2/projects/seasonal_pseudo_change/datasets/rawframes'
        ),
        filename_tmpl='img_{:04d}.jpg',
        pipeline=[
            dict(
                clip_len=8,
                frame_interval=1,
                num_clips=1,
                test_mode=True,
                type='SampleFrames'),
            dict(type='RawFrameDecode'),
            dict(scale=(
                -1,
                256,
            ), type='Resize'),
            dict(crop_size=224, type='CenterCrop'),
            dict(input_format='NCTHW', type='FormatShape'),
            dict(type='PackActionInputs'),
        ],
        test_mode=True,
        type='RawframeDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(type='AccMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    type='ActionVisualizer', vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = 'F:\\zyp\\Thesis source code\\mmaction2\\projects\\seasonal_pseudo_change\\work_dirs'

2025/05/28 15:36:52 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2025/05/28 15:36:52 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SyncBuffersHook                    
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SyncBuffersHook                    
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.patch_embed.proj.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.patch_embed.proj.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.patch_embed.proj.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.patch_embed.proj.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.patch_embed.norm.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.patch_embed.norm.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.patch_embed.norm.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.patch_embed.norm.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.norm1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.norm1.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.norm1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.norm1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.attn.relative_position_bias_table: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.attn.relative_position_bias_table: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.attn.qkv.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.attn.qkv.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.attn.qkv.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.attn.qkv.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.attn.proj.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.attn.proj.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.attn.proj.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.attn.proj.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.norm2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.norm2.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.norm2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.norm2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.mlp.fc1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.mlp.fc1.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.mlp.fc1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.mlp.fc1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.mlp.fc2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.mlp.fc2.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.mlp.fc2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.0.mlp.fc2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.norm1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.norm1.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.norm1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.norm1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.attn.relative_position_bias_table: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.attn.relative_position_bias_table: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.attn.qkv.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.attn.qkv.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.attn.qkv.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.attn.qkv.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.attn.proj.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.attn.proj.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.attn.proj.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.attn.proj.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.norm2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.norm2.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.norm2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.norm2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.mlp.fc1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.mlp.fc1.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.mlp.fc1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.mlp.fc1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.mlp.fc2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.mlp.fc2.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.mlp.fc2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.blocks.1.mlp.fc2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.downsample.reduction.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.downsample.reduction.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.downsample.norm.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.downsample.norm.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.downsample.norm.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.0.downsample.norm.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.norm1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.norm1.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.norm1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.norm1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.attn.relative_position_bias_table: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.attn.relative_position_bias_table: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.attn.qkv.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.attn.qkv.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.attn.qkv.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.attn.qkv.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.attn.proj.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.attn.proj.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.attn.proj.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.attn.proj.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.norm2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.norm2.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.norm2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.norm2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.mlp.fc1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.mlp.fc1.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.mlp.fc1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.mlp.fc1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.mlp.fc2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.mlp.fc2.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.mlp.fc2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.0.mlp.fc2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.norm1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.norm1.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.norm1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.norm1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.attn.relative_position_bias_table: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.attn.relative_position_bias_table: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.attn.qkv.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.attn.qkv.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.attn.qkv.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.attn.qkv.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.attn.proj.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.attn.proj.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.attn.proj.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.attn.proj.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.norm2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.norm2.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.norm2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.norm2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.mlp.fc1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.mlp.fc1.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.mlp.fc1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.mlp.fc1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.mlp.fc2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.mlp.fc2.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.mlp.fc2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.blocks.1.mlp.fc2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.downsample.reduction.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.downsample.reduction.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.downsample.norm.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.downsample.norm.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.downsample.norm.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.1.downsample.norm.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.norm1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.norm1.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.norm1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.norm1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.attn.relative_position_bias_table: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.attn.relative_position_bias_table: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.attn.qkv.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.attn.qkv.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.attn.qkv.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.attn.qkv.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.attn.proj.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.attn.proj.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.attn.proj.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.attn.proj.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.norm2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.norm2.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.norm2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.norm2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.mlp.fc1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.mlp.fc1.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.mlp.fc1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.mlp.fc1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.mlp.fc2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.mlp.fc2.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.mlp.fc2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.0.mlp.fc2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.norm1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.norm1.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.norm1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.norm1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.attn.relative_position_bias_table: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.attn.relative_position_bias_table: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.attn.qkv.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.attn.qkv.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.attn.qkv.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.attn.qkv.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.attn.proj.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.attn.proj.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.attn.proj.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.attn.proj.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.norm2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.norm2.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.norm2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.norm2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.mlp.fc1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.mlp.fc1.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.mlp.fc1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.mlp.fc1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.mlp.fc2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.mlp.fc2.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.mlp.fc2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.1.mlp.fc2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.norm1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.norm1.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.norm1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.norm1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.attn.relative_position_bias_table: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.attn.relative_position_bias_table: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.attn.qkv.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.attn.qkv.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.attn.qkv.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.attn.qkv.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.attn.proj.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.attn.proj.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.attn.proj.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.attn.proj.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.norm2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.norm2.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.norm2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.norm2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.mlp.fc1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.mlp.fc1.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.mlp.fc1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.mlp.fc1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.mlp.fc2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.mlp.fc2.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.mlp.fc2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.2.mlp.fc2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.norm1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.norm1.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.norm1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.norm1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.attn.relative_position_bias_table: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.attn.relative_position_bias_table: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.attn.qkv.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.attn.qkv.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.attn.qkv.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.attn.qkv.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.attn.proj.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.attn.proj.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.attn.proj.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.attn.proj.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.norm2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.norm2.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.norm2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.norm2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.mlp.fc1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.mlp.fc1.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.mlp.fc1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.mlp.fc1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.mlp.fc2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.mlp.fc2.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.mlp.fc2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.3.mlp.fc2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.norm1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.norm1.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.norm1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.norm1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.attn.relative_position_bias_table: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.attn.relative_position_bias_table: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.attn.qkv.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.attn.qkv.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.attn.qkv.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.attn.qkv.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.attn.proj.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.attn.proj.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.attn.proj.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.attn.proj.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.norm2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.norm2.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.norm2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.norm2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.mlp.fc1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.mlp.fc1.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.mlp.fc1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.mlp.fc1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.mlp.fc2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.mlp.fc2.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.mlp.fc2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.4.mlp.fc2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.norm1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.norm1.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.norm1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.norm1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.attn.relative_position_bias_table: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.attn.relative_position_bias_table: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.attn.qkv.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.attn.qkv.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.attn.qkv.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.attn.qkv.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.attn.proj.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.attn.proj.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.attn.proj.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.attn.proj.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.norm2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.norm2.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.norm2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.norm2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.mlp.fc1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.mlp.fc1.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.mlp.fc1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.mlp.fc1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.mlp.fc2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.mlp.fc2.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.mlp.fc2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.blocks.5.mlp.fc2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.downsample.reduction.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.downsample.reduction.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.downsample.norm.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.downsample.norm.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.downsample.norm.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.2.downsample.norm.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.norm1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.norm1.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.norm1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.norm1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.attn.relative_position_bias_table: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.attn.relative_position_bias_table: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.attn.qkv.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.attn.qkv.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.attn.qkv.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.attn.qkv.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.attn.proj.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.attn.proj.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.attn.proj.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.attn.proj.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.norm2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.norm2.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.norm2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.norm2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.mlp.fc1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.mlp.fc1.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.mlp.fc1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.mlp.fc1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.mlp.fc2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.mlp.fc2.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.mlp.fc2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.0.mlp.fc2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.norm1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.norm1.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.norm1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.norm1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.attn.relative_position_bias_table: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.attn.relative_position_bias_table: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.attn.qkv.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.attn.qkv.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.attn.qkv.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.attn.qkv.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.attn.proj.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.attn.proj.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.attn.proj.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.attn.proj.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.norm2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.norm2.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.norm2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.norm2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.mlp.fc1.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.mlp.fc1.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.mlp.fc1.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.mlp.fc1.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.mlp.fc2.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.mlp.fc2.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.mlp.fc2.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.layers.3.blocks.1.mlp.fc2.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.norm3.weight: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.norm3.weight: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.norm3.bias: lr = 0.0001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.backbone.norm3.bias: weight_decay = 0.0
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.cls_head.fc_cls.weight: lr = 0.001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.cls_head.fc_cls.weight: weight_decay = 0.02
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.cls_head.fc_cls.bias: lr = 0.001
2025/05/28 15:36:53 - mmengine - INFO - paramwise_options -- base.cls_head.fc_cls.bias: weight_decay = 0.0
2025/05/28 15:36:54 - mmengine - INFO - load model from: F:/zyp/Thesis source code/mmaction2/projects/seasonal_pseudo_change/pretrained/videoswin/swin_tiny_patch244_window877_kinetics400_1k_converted.pth
2025/05/28 15:36:54 - mmengine - INFO - Loads checkpoint by local backend from path: F:/zyp/Thesis source code/mmaction2/projects/seasonal_pseudo_change/pretrained/videoswin/swin_tiny_patch244_window877_kinetics400_1k_converted.pth
2025/05/28 15:36:54 - mmengine - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: model

missing keys in source state_dict: patch_embed.proj.weight, patch_embed.proj.bias, patch_embed.norm.weight, patch_embed.norm.bias, layers.0.blocks.0.norm1.weight, layers.0.blocks.0.norm1.bias, layers.0.blocks.0.attn.relative_position_bias_table, layers.0.blocks.0.attn.relative_position_index, layers.0.blocks.0.attn.qkv.weight, layers.0.blocks.0.attn.qkv.bias, layers.0.blocks.0.attn.proj.weight, layers.0.blocks.0.attn.proj.bias, layers.0.blocks.0.norm2.weight, layers.0.blocks.0.norm2.bias, layers.0.blocks.0.mlp.fc1.weight, layers.0.blocks.0.mlp.fc1.bias, layers.0.blocks.0.mlp.fc2.weight, layers.0.blocks.0.mlp.fc2.bias, layers.0.blocks.1.norm1.weight, layers.0.blocks.1.norm1.bias, layers.0.blocks.1.attn.relative_position_bias_table, layers.0.blocks.1.attn.relative_position_index, layers.0.blocks.1.attn.qkv.weight, layers.0.blocks.1.attn.qkv.bias, layers.0.blocks.1.attn.proj.weight, layers.0.blocks.1.attn.proj.bias, layers.0.blocks.1.norm2.weight, layers.0.blocks.1.norm2.bias, layers.0.blocks.1.mlp.fc1.weight, layers.0.blocks.1.mlp.fc1.bias, layers.0.blocks.1.mlp.fc2.weight, layers.0.blocks.1.mlp.fc2.bias, layers.0.downsample.reduction.weight, layers.0.downsample.norm.weight, layers.0.downsample.norm.bias, layers.1.blocks.0.norm1.weight, layers.1.blocks.0.norm1.bias, layers.1.blocks.0.attn.relative_position_bias_table, layers.1.blocks.0.attn.relative_position_index, layers.1.blocks.0.attn.qkv.weight, layers.1.blocks.0.attn.qkv.bias, layers.1.blocks.0.attn.proj.weight, layers.1.blocks.0.attn.proj.bias, layers.1.blocks.0.norm2.weight, layers.1.blocks.0.norm2.bias, layers.1.blocks.0.mlp.fc1.weight, layers.1.blocks.0.mlp.fc1.bias, layers.1.blocks.0.mlp.fc2.weight, layers.1.blocks.0.mlp.fc2.bias, layers.1.blocks.1.norm1.weight, layers.1.blocks.1.norm1.bias, layers.1.blocks.1.attn.relative_position_bias_table, layers.1.blocks.1.attn.relative_position_index, layers.1.blocks.1.attn.qkv.weight, layers.1.blocks.1.attn.qkv.bias, layers.1.blocks.1.attn.proj.weight, layers.1.blocks.1.attn.proj.bias, layers.1.blocks.1.norm2.weight, layers.1.blocks.1.norm2.bias, layers.1.blocks.1.mlp.fc1.weight, layers.1.blocks.1.mlp.fc1.bias, layers.1.blocks.1.mlp.fc2.weight, layers.1.blocks.1.mlp.fc2.bias, layers.1.downsample.reduction.weight, layers.1.downsample.norm.weight, layers.1.downsample.norm.bias, layers.2.blocks.0.norm1.weight, layers.2.blocks.0.norm1.bias, layers.2.blocks.0.attn.relative_position_bias_table, layers.2.blocks.0.attn.relative_position_index, layers.2.blocks.0.attn.qkv.weight, layers.2.blocks.0.attn.qkv.bias, layers.2.blocks.0.attn.proj.weight, layers.2.blocks.0.attn.proj.bias, layers.2.blocks.0.norm2.weight, layers.2.blocks.0.norm2.bias, layers.2.blocks.0.mlp.fc1.weight, layers.2.blocks.0.mlp.fc1.bias, layers.2.blocks.0.mlp.fc2.weight, layers.2.blocks.0.mlp.fc2.bias, layers.2.blocks.1.norm1.weight, layers.2.blocks.1.norm1.bias, layers.2.blocks.1.attn.relative_position_bias_table, layers.2.blocks.1.attn.relative_position_index, layers.2.blocks.1.attn.qkv.weight, layers.2.blocks.1.attn.qkv.bias, layers.2.blocks.1.attn.proj.weight, layers.2.blocks.1.attn.proj.bias, layers.2.blocks.1.norm2.weight, layers.2.blocks.1.norm2.bias, layers.2.blocks.1.mlp.fc1.weight, layers.2.blocks.1.mlp.fc1.bias, layers.2.blocks.1.mlp.fc2.weight, layers.2.blocks.1.mlp.fc2.bias, layers.2.blocks.2.norm1.weight, layers.2.blocks.2.norm1.bias, layers.2.blocks.2.attn.relative_position_bias_table, layers.2.blocks.2.attn.relative_position_index, layers.2.blocks.2.attn.qkv.weight, layers.2.blocks.2.attn.qkv.bias, layers.2.blocks.2.attn.proj.weight, layers.2.blocks.2.attn.proj.bias, layers.2.blocks.2.norm2.weight, layers.2.blocks.2.norm2.bias, layers.2.blocks.2.mlp.fc1.weight, layers.2.blocks.2.mlp.fc1.bias, layers.2.blocks.2.mlp.fc2.weight, layers.2.blocks.2.mlp.fc2.bias, layers.2.blocks.3.norm1.weight, layers.2.blocks.3.norm1.bias, layers.2.blocks.3.attn.relative_position_bias_table, layers.2.blocks.3.attn.relative_position_index, layers.2.blocks.3.attn.qkv.weight, layers.2.blocks.3.attn.qkv.bias, layers.2.blocks.3.attn.proj.weight, layers.2.blocks.3.attn.proj.bias, layers.2.blocks.3.norm2.weight, layers.2.blocks.3.norm2.bias, layers.2.blocks.3.mlp.fc1.weight, layers.2.blocks.3.mlp.fc1.bias, layers.2.blocks.3.mlp.fc2.weight, layers.2.blocks.3.mlp.fc2.bias, layers.2.blocks.4.norm1.weight, layers.2.blocks.4.norm1.bias, layers.2.blocks.4.attn.relative_position_bias_table, layers.2.blocks.4.attn.relative_position_index, layers.2.blocks.4.attn.qkv.weight, layers.2.blocks.4.attn.qkv.bias, layers.2.blocks.4.attn.proj.weight, layers.2.blocks.4.attn.proj.bias, layers.2.blocks.4.norm2.weight, layers.2.blocks.4.norm2.bias, layers.2.blocks.4.mlp.fc1.weight, layers.2.blocks.4.mlp.fc1.bias, layers.2.blocks.4.mlp.fc2.weight, layers.2.blocks.4.mlp.fc2.bias, layers.2.blocks.5.norm1.weight, layers.2.blocks.5.norm1.bias, layers.2.blocks.5.attn.relative_position_bias_table, layers.2.blocks.5.attn.relative_position_index, layers.2.blocks.5.attn.qkv.weight, layers.2.blocks.5.attn.qkv.bias, layers.2.blocks.5.attn.proj.weight, layers.2.blocks.5.attn.proj.bias, layers.2.blocks.5.norm2.weight, layers.2.blocks.5.norm2.bias, layers.2.blocks.5.mlp.fc1.weight, layers.2.blocks.5.mlp.fc1.bias, layers.2.blocks.5.mlp.fc2.weight, layers.2.blocks.5.mlp.fc2.bias, layers.2.downsample.reduction.weight, layers.2.downsample.norm.weight, layers.2.downsample.norm.bias, layers.3.blocks.0.norm1.weight, layers.3.blocks.0.norm1.bias, layers.3.blocks.0.attn.relative_position_bias_table, layers.3.blocks.0.attn.relative_position_index, layers.3.blocks.0.attn.qkv.weight, layers.3.blocks.0.attn.qkv.bias, layers.3.blocks.0.attn.proj.weight, layers.3.blocks.0.attn.proj.bias, layers.3.blocks.0.norm2.weight, layers.3.blocks.0.norm2.bias, layers.3.blocks.0.mlp.fc1.weight, layers.3.blocks.0.mlp.fc1.bias, layers.3.blocks.0.mlp.fc2.weight, layers.3.blocks.0.mlp.fc2.bias, layers.3.blocks.1.norm1.weight, layers.3.blocks.1.norm1.bias, layers.3.blocks.1.attn.relative_position_bias_table, layers.3.blocks.1.attn.relative_position_index, layers.3.blocks.1.attn.qkv.weight, layers.3.blocks.1.attn.qkv.bias, layers.3.blocks.1.attn.proj.weight, layers.3.blocks.1.attn.proj.bias, layers.3.blocks.1.norm2.weight, layers.3.blocks.1.norm2.bias, layers.3.blocks.1.mlp.fc1.weight, layers.3.blocks.1.mlp.fc1.bias, layers.3.blocks.1.mlp.fc2.weight, layers.3.blocks.1.mlp.fc2.bias, norm3.weight, norm3.bias

Name of parameter - Initialization information

backbone.patch_embed.proj.weight - torch.Size([96, 3, 2, 4, 4]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.patch_embed.proj.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.patch_embed.norm.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.patch_embed.norm.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.0.norm1.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.0.norm1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.0.attn.relative_position_bias_table - torch.Size([2535, 3]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.0.attn.qkv.weight - torch.Size([288, 96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.0.attn.qkv.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.0.attn.proj.weight - torch.Size([96, 96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.0.attn.proj.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.0.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.0.norm2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.0.mlp.fc1.weight - torch.Size([384, 96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.0.mlp.fc1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.0.mlp.fc2.weight - torch.Size([96, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.0.mlp.fc2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.1.norm1.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.1.norm1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.1.attn.relative_position_bias_table - torch.Size([2535, 3]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.1.attn.qkv.weight - torch.Size([288, 96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.1.attn.qkv.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.1.attn.proj.weight - torch.Size([96, 96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.1.attn.proj.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.1.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.1.norm2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.1.mlp.fc1.weight - torch.Size([384, 96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.1.mlp.fc1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.1.mlp.fc2.weight - torch.Size([96, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.blocks.1.mlp.fc2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.downsample.reduction.weight - torch.Size([192, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.downsample.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.0.downsample.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.0.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.0.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.0.attn.relative_position_bias_table - torch.Size([2535, 6]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.0.attn.qkv.weight - torch.Size([576, 192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.0.attn.qkv.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.0.attn.proj.weight - torch.Size([192, 192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.0.attn.proj.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.0.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.0.norm2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.0.mlp.fc1.weight - torch.Size([768, 192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.0.mlp.fc1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.0.mlp.fc2.weight - torch.Size([192, 768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.0.mlp.fc2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.1.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.1.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.1.attn.relative_position_bias_table - torch.Size([2535, 6]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.1.attn.qkv.weight - torch.Size([576, 192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.1.attn.qkv.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.1.attn.proj.weight - torch.Size([192, 192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.1.attn.proj.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.1.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.1.norm2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.1.mlp.fc1.weight - torch.Size([768, 192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.1.mlp.fc1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.1.mlp.fc2.weight - torch.Size([192, 768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.blocks.1.mlp.fc2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.downsample.reduction.weight - torch.Size([384, 768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.downsample.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.1.downsample.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.0.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.0.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.0.attn.relative_position_bias_table - torch.Size([2535, 12]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.0.attn.qkv.weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.0.attn.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.0.attn.proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.0.attn.proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.0.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.0.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.0.mlp.fc1.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.0.mlp.fc1.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.0.mlp.fc2.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.0.mlp.fc2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.1.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.1.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.1.attn.relative_position_bias_table - torch.Size([2535, 12]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.1.attn.qkv.weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.1.attn.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.1.attn.proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.1.attn.proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.1.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.1.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.1.mlp.fc1.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.1.mlp.fc1.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.1.mlp.fc2.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.1.mlp.fc2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.2.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.2.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.2.attn.relative_position_bias_table - torch.Size([2535, 12]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.2.attn.qkv.weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.2.attn.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.2.attn.proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.2.attn.proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.2.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.2.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.2.mlp.fc1.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.2.mlp.fc1.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.2.mlp.fc2.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.2.mlp.fc2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.3.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.3.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.3.attn.relative_position_bias_table - torch.Size([2535, 12]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.3.attn.qkv.weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.3.attn.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.3.attn.proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.3.attn.proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.3.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.3.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.3.mlp.fc1.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.3.mlp.fc1.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.3.mlp.fc2.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.3.mlp.fc2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.4.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.4.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.4.attn.relative_position_bias_table - torch.Size([2535, 12]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.4.attn.qkv.weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.4.attn.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.4.attn.proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.4.attn.proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.4.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.4.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.4.mlp.fc1.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.4.mlp.fc1.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.4.mlp.fc2.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.4.mlp.fc2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.5.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.5.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.5.attn.relative_position_bias_table - torch.Size([2535, 12]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.5.attn.qkv.weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.5.attn.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.5.attn.proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.5.attn.proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.5.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.5.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.5.mlp.fc1.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.5.mlp.fc1.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.5.mlp.fc2.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.blocks.5.mlp.fc2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.downsample.reduction.weight - torch.Size([768, 1536]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.downsample.norm.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.2.downsample.norm.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.0.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.0.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.0.attn.relative_position_bias_table - torch.Size([2535, 24]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.0.attn.qkv.weight - torch.Size([2304, 768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.0.attn.qkv.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.0.attn.proj.weight - torch.Size([768, 768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.0.attn.proj.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.0.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.0.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.0.mlp.fc1.weight - torch.Size([3072, 768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.0.mlp.fc1.bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.0.mlp.fc2.weight - torch.Size([768, 3072]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.0.mlp.fc2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.1.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.1.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.1.attn.relative_position_bias_table - torch.Size([2535, 24]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.1.attn.qkv.weight - torch.Size([2304, 768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.1.attn.qkv.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.1.attn.proj.weight - torch.Size([768, 768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.1.attn.proj.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.1.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.1.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.1.mlp.fc1.weight - torch.Size([3072, 768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.1.mlp.fc1.bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.1.mlp.fc2.weight - torch.Size([768, 3072]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.layers.3.blocks.1.mlp.fc2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.norm3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

backbone.norm3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of Recognizer3D  

cls_head.fc_cls.weight - torch.Size([2, 768]): 
Initialized by user-defined `init_weights` in I3DHead  

cls_head.fc_cls.bias - torch.Size([2]): 
Initialized by user-defined `init_weights` in I3DHead  
2025/05/28 15:36:54 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/05/28 15:36:54 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/05/28 15:36:54 - mmengine - INFO - Checkpoints will be saved to F:\zyp\Thesis source code\mmaction2\projects\seasonal_pseudo_change\work_dirs.
2025/05/28 15:37:22 - mmengine - INFO - Epoch(train)  [1][10/37]  base_lr: 1.8901e-04 lr: 1.8901e-05  eta: 1:25:45  time: 2.7963  data_time: 1.7856  memory: 2158  loss: 0.7976  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7976
2025/05/28 15:37:32 - mmengine - INFO - Epoch(train)  [1][20/37]  base_lr: 2.8791e-04 lr: 2.8791e-05  eta: 0:57:18  time: 1.8787  data_time: 0.8948  memory: 2158  loss: 0.8741  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8741
2025/05/28 15:37:41 - mmengine - INFO - Epoch(train)  [1][30/37]  base_lr: 3.8681e-04 lr: 3.8681e-05  eta: 0:47:44  time: 0.9630  data_time: 0.0039  memory: 2158  loss: 0.7757  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7757
2025/05/28 15:37:48 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:37:48 - mmengine - INFO - Epoch(train)  [1][37/37]  base_lr: 4.5604e-04 lr: 4.5604e-05  eta: 0:44:03  time: 0.9631  data_time: 0.0039  memory: 2158  loss: 0.7567  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7567
2025/05/28 15:37:48 - mmengine - INFO - Saving checkpoint at 1 epochs
2025/05/28 15:38:02 - mmengine - INFO - Epoch(val)  [1][10/10]    eta: 0:00:00  time: 0.9097  data_time: 0.5453  memory: 798  
2025/05/28 15:38:02 - mmengine - INFO - Epoch(val) [1][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.5453  time: 0.9097
2025/05/28 15:38:04 - mmengine - INFO - The best checkpoint with 0.5526 acc/top1 at 1 epoch is saved to best_acc_top1_epoch_1.pth.
2025/05/28 15:38:19 - mmengine - INFO - Epoch(train)  [2][10/37]  base_lr: 5.5343e-04 lr: 5.5343e-05  eta: 0:40:39  time: 0.9631  data_time: 0.0054  memory: 2158  loss: 0.7225  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7225
2025/05/28 15:38:28 - mmengine - INFO - Epoch(train)  [2][20/37]  base_lr: 6.5206e-04 lr: 6.5206e-05  eta: 0:38:23  time: 0.9635  data_time: 0.0055  memory: 2158  loss: 0.6865  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6865
2025/05/28 15:38:38 - mmengine - INFO - Epoch(train)  [2][30/37]  base_lr: 7.5069e-04 lr: 7.5069e-05  eta: 0:36:44  time: 0.9617  data_time: 0.0040  memory: 2158  loss: 0.7548  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7548
2025/05/28 15:38:45 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:38:45 - mmengine - INFO - Epoch(train)  [2][37/37]  base_lr: 8.1973e-04 lr: 8.1973e-05  eta: 0:35:50  time: 0.9626  data_time: 0.0040  memory: 2158  loss: 0.8432  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8432
2025/05/28 15:38:45 - mmengine - INFO - Saving checkpoint at 2 epochs
2025/05/28 15:38:53 - mmengine - INFO - Epoch(val)  [2][10/10]    eta: 0:00:00  time: 0.6307  data_time: 0.2747  memory: 798  
2025/05/28 15:38:53 - mmengine - INFO - Epoch(val) [2][10/10]    acc/top1: 0.4474  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0039  time: 0.3366
2025/05/28 15:39:03 - mmengine - INFO - Epoch(train)  [3][10/37]  base_lr: 9.1082e-04 lr: 9.1082e-05  eta: 0:34:47  time: 0.9685  data_time: 0.0058  memory: 2158  loss: 0.7940  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7940
2025/05/28 15:39:13 - mmengine - INFO - Epoch(train)  [3][20/37]  base_lr: 9.8907e-04 lr: 9.8907e-05  eta: 0:33:55  time: 0.9675  data_time: 0.0057  memory: 2158  loss: 0.7726  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7726
2025/05/28 15:39:22 - mmengine - INFO - Epoch(train)  [3][30/37]  base_lr: 9.8907e-04 lr: 9.8907e-05  eta: 0:33:10  time: 0.9629  data_time: 0.0037  memory: 2158  loss: 0.7194  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7194
2025/05/28 15:39:29 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:39:29 - mmengine - INFO - Epoch(train)  [3][37/37]  base_lr: 9.8907e-04 lr: 9.8907e-05  eta: 0:32:43  time: 0.9631  data_time: 0.0034  memory: 2158  loss: 0.7196  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7196
2025/05/28 15:39:29 - mmengine - INFO - Saving checkpoint at 3 epochs
2025/05/28 15:39:37 - mmengine - INFO - Epoch(val)  [3][10/10]    eta: 0:00:00  time: 0.3457  data_time: 0.0043  memory: 798  
2025/05/28 15:39:37 - mmengine - INFO - Epoch(val) [3][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0043  time: 0.3254
2025/05/28 15:39:47 - mmengine - INFO - Epoch(train)  [4][10/37]  base_lr: 9.7553e-04 lr: 9.7553e-05  eta: 0:32:08  time: 0.9656  data_time: 0.0049  memory: 2158  loss: 0.7557  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7557
2025/05/28 15:39:57 - mmengine - INFO - Epoch(train)  [4][20/37]  base_lr: 9.7553e-04 lr: 9.7553e-05  eta: 0:31:37  time: 0.9659  data_time: 0.0049  memory: 2158  loss: 0.7814  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7814
2025/05/28 15:40:06 - mmengine - INFO - Epoch(train)  [4][30/37]  base_lr: 9.7553e-04 lr: 9.7553e-05  eta: 0:31:10  time: 0.9648  data_time: 0.0037  memory: 2158  loss: 0.7242  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7242
2025/05/28 15:40:13 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:40:13 - mmengine - INFO - Epoch(train)  [4][37/37]  base_lr: 9.7553e-04 lr: 9.7553e-05  eta: 0:30:51  time: 0.9639  data_time: 0.0038  memory: 2158  loss: 0.7651  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7651
2025/05/28 15:40:13 - mmengine - INFO - Saving checkpoint at 4 epochs
2025/05/28 15:40:21 - mmengine - INFO - Epoch(val)  [4][10/10]    eta: 0:00:00  time: 0.3480  data_time: 0.0045  memory: 798  
2025/05/28 15:40:21 - mmengine - INFO - Epoch(val) [4][10/10]    acc/top1: 0.5000  acc/top5: 1.0000  acc/mean1: 0.4580  data_time: 0.0041  time: 0.3405
2025/05/28 15:40:31 - mmengine - INFO - Epoch(train)  [5][10/37]  base_lr: 9.5677e-04 lr: 9.5677e-05  eta: 0:30:27  time: 0.9643  data_time: 0.0048  memory: 2158  loss: 0.7705  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7705
2025/05/28 15:40:41 - mmengine - INFO - Epoch(train)  [5][20/37]  base_lr: 9.5677e-04 lr: 9.5677e-05  eta: 0:30:05  time: 0.9668  data_time: 0.0047  memory: 2158  loss: 0.7530  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7530
2025/05/28 15:40:50 - mmengine - INFO - Epoch(train)  [5][30/37]  base_lr: 9.5677e-04 lr: 9.5677e-05  eta: 0:29:44  time: 0.9653  data_time: 0.0034  memory: 2158  loss: 0.7503  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7503
2025/05/28 15:40:57 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:40:57 - mmengine - INFO - Epoch(train)  [5][37/37]  base_lr: 9.5677e-04 lr: 9.5677e-05  eta: 0:29:30  time: 0.9633  data_time: 0.0033  memory: 2158  loss: 0.7676  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7676
2025/05/28 15:40:57 - mmengine - INFO - Saving checkpoint at 5 epochs
2025/05/28 15:41:05 - mmengine - INFO - Epoch(val)  [5][10/10]    eta: 0:00:00  time: 0.3477  data_time: 0.0042  memory: 798  
2025/05/28 15:41:05 - mmengine - INFO - Epoch(val) [5][10/10]    acc/top1: 0.4474  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0039  time: 0.3250
2025/05/28 15:41:15 - mmengine - INFO - Epoch(train)  [6][10/37]  base_lr: 9.3301e-04 lr: 9.3301e-05  eta: 0:29:11  time: 0.9647  data_time: 0.0048  memory: 2158  loss: 0.8172  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8172
2025/05/28 15:41:25 - mmengine - INFO - Epoch(train)  [6][20/37]  base_lr: 9.3301e-04 lr: 9.3301e-05  eta: 0:28:53  time: 0.9630  data_time: 0.0051  memory: 2158  loss: 0.8444  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8444
2025/05/28 15:41:34 - mmengine - INFO - Epoch(train)  [6][30/37]  base_lr: 9.3301e-04 lr: 9.3301e-05  eta: 0:28:35  time: 0.9613  data_time: 0.0037  memory: 2158  loss: 0.8749  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8749
2025/05/28 15:41:41 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:41:41 - mmengine - INFO - Epoch(train)  [6][37/37]  base_lr: 9.3301e-04 lr: 9.3301e-05  eta: 0:28:23  time: 0.9632  data_time: 0.0035  memory: 2158  loss: 0.9164  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.9164
2025/05/28 15:41:41 - mmengine - INFO - Saving checkpoint at 6 epochs
2025/05/28 15:41:49 - mmengine - INFO - Epoch(val)  [6][10/10]    eta: 0:00:00  time: 0.3401  data_time: 0.0041  memory: 798  
2025/05/28 15:41:49 - mmengine - INFO - Epoch(val) [6][10/10]    acc/top1: 0.4474  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0040  time: 0.3267
2025/05/28 15:41:59 - mmengine - INFO - Epoch(train)  [7][10/37]  base_lr: 9.0451e-04 lr: 9.0451e-05  eta: 0:28:08  time: 0.9659  data_time: 0.0052  memory: 2158  loss: 1.0176  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.0176
2025/05/28 15:42:08 - mmengine - INFO - Epoch(train)  [7][20/37]  base_lr: 9.0451e-04 lr: 9.0451e-05  eta: 0:27:52  time: 0.9666  data_time: 0.0051  memory: 2158  loss: 1.0164  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.0164
2025/05/28 15:42:18 - mmengine - INFO - Epoch(train)  [7][30/37]  base_lr: 9.0451e-04 lr: 9.0451e-05  eta: 0:27:37  time: 0.9642  data_time: 0.0035  memory: 2158  loss: 1.0252  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.0252
2025/05/28 15:42:25 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:42:25 - mmengine - INFO - Epoch(train)  [7][37/37]  base_lr: 9.0451e-04 lr: 9.0451e-05  eta: 0:27:26  time: 0.9640  data_time: 0.0035  memory: 2158  loss: 0.9516  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9516
2025/05/28 15:42:25 - mmengine - INFO - Saving checkpoint at 7 epochs
2025/05/28 15:42:33 - mmengine - INFO - Epoch(val)  [7][10/10]    eta: 0:00:00  time: 0.3404  data_time: 0.0046  memory: 798  
2025/05/28 15:42:33 - mmengine - INFO - Epoch(val) [7][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0047  time: 0.3256
2025/05/28 15:42:43 - mmengine - INFO - Epoch(train)  [8][10/37]  base_lr: 8.7157e-04 lr: 8.7157e-05  eta: 0:27:12  time: 0.9659  data_time: 0.0048  memory: 2158  loss: 0.7893  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7893
2025/05/28 15:42:52 - mmengine - INFO - Epoch(train)  [8][20/37]  base_lr: 8.7157e-04 lr: 8.7157e-05  eta: 0:26:58  time: 0.9649  data_time: 0.0049  memory: 2158  loss: 0.7376  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7376
2025/05/28 15:43:02 - mmengine - INFO - Epoch(train)  [8][30/37]  base_lr: 8.7157e-04 lr: 8.7157e-05  eta: 0:26:44  time: 0.9654  data_time: 0.0036  memory: 2158  loss: 0.8031  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8031
2025/05/28 15:43:09 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:43:09 - mmengine - INFO - Epoch(train)  [8][37/37]  base_lr: 8.7157e-04 lr: 8.7157e-05  eta: 0:26:34  time: 0.9651  data_time: 0.0035  memory: 2158  loss: 0.7593  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7593
2025/05/28 15:43:09 - mmengine - INFO - Saving checkpoint at 8 epochs
2025/05/28 15:43:17 - mmengine - INFO - Epoch(val)  [8][10/10]    eta: 0:00:00  time: 0.3449  data_time: 0.0050  memory: 798  
2025/05/28 15:43:17 - mmengine - INFO - Epoch(val) [8][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0049  time: 0.3351
2025/05/28 15:43:27 - mmengine - INFO - Epoch(train)  [9][10/37]  base_lr: 8.3457e-04 lr: 8.3457e-05  eta: 0:26:21  time: 0.9649  data_time: 0.0047  memory: 2158  loss: 0.7102  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7102
2025/05/28 15:43:36 - mmengine - INFO - Epoch(train)  [9][20/37]  base_lr: 8.3457e-04 lr: 8.3457e-05  eta: 0:26:08  time: 0.9623  data_time: 0.0048  memory: 2158  loss: 0.7439  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7439
2025/05/28 15:43:46 - mmengine - INFO - Epoch(train)  [9][30/37]  base_lr: 8.3457e-04 lr: 8.3457e-05  eta: 0:25:55  time: 0.9616  data_time: 0.0035  memory: 2158  loss: 0.7910  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7910
2025/05/28 15:43:53 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:43:53 - mmengine - INFO - Epoch(train)  [9][37/37]  base_lr: 8.3457e-04 lr: 8.3457e-05  eta: 0:25:46  time: 0.9617  data_time: 0.0034  memory: 2158  loss: 0.7949  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7949
2025/05/28 15:43:53 - mmengine - INFO - Saving checkpoint at 9 epochs
2025/05/28 15:44:01 - mmengine - INFO - Epoch(val)  [9][10/10]    eta: 0:00:00  time: 0.3530  data_time: 0.0050  memory: 798  
2025/05/28 15:44:01 - mmengine - INFO - Epoch(val) [9][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0046  time: 0.3404
2025/05/28 15:44:11 - mmengine - INFO - Epoch(train) [10][10/37]  base_lr: 7.9389e-04 lr: 7.9389e-05  eta: 0:25:33  time: 0.9631  data_time: 0.0047  memory: 2158  loss: 0.7890  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7890
2025/05/28 15:44:21 - mmengine - INFO - Epoch(train) [10][20/37]  base_lr: 7.9389e-04 lr: 7.9389e-05  eta: 0:25:21  time: 0.9636  data_time: 0.0048  memory: 2158  loss: 0.7793  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7793
2025/05/28 15:44:30 - mmengine - INFO - Epoch(train) [10][30/37]  base_lr: 7.9389e-04 lr: 7.9389e-05  eta: 0:25:08  time: 0.9623  data_time: 0.0035  memory: 2158  loss: 0.7291  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7291
2025/05/28 15:44:37 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:44:37 - mmengine - INFO - Epoch(train) [10][37/37]  base_lr: 7.9389e-04 lr: 7.9389e-05  eta: 0:25:00  time: 0.9632  data_time: 0.0035  memory: 2158  loss: 0.7281  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7281
2025/05/28 15:44:37 - mmengine - INFO - Saving checkpoint at 10 epochs
2025/05/28 15:44:46 - mmengine - INFO - Epoch(val) [10][10/10]    eta: 0:00:00  time: 0.3479  data_time: 0.0049  memory: 798  
2025/05/28 15:44:46 - mmengine - INFO - Epoch(val) [10][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0046  time: 0.3256
2025/05/28 15:44:55 - mmengine - INFO - Epoch(train) [11][10/37]  base_lr: 7.5000e-04 lr: 7.5000e-05  eta: 0:24:48  time: 0.9653  data_time: 0.0045  memory: 2158  loss: 0.7627  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7627
2025/05/28 15:45:05 - mmengine - INFO - Epoch(train) [11][20/37]  base_lr: 7.5000e-04 lr: 7.5000e-05  eta: 0:24:36  time: 0.9672  data_time: 0.0045  memory: 2158  loss: 0.7640  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7640
2025/05/28 15:45:15 - mmengine - INFO - Epoch(train) [11][30/37]  base_lr: 7.5000e-04 lr: 7.5000e-05  eta: 0:24:24  time: 0.9648  data_time: 0.0034  memory: 2158  loss: 0.7363  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7363
2025/05/28 15:45:21 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:45:21 - mmengine - INFO - Epoch(train) [11][37/37]  base_lr: 7.5000e-04 lr: 7.5000e-05  eta: 0:24:16  time: 0.9631  data_time: 0.0033  memory: 2158  loss: 0.7561  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7561
2025/05/28 15:45:21 - mmengine - INFO - Saving checkpoint at 11 epochs
2025/05/28 15:45:30 - mmengine - INFO - Epoch(val) [11][10/10]    eta: 0:00:00  time: 0.3484  data_time: 0.0046  memory: 798  
2025/05/28 15:45:30 - mmengine - INFO - Epoch(val) [11][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0041  time: 0.3413
2025/05/28 15:45:40 - mmengine - INFO - Epoch(train) [12][10/37]  base_lr: 7.0337e-04 lr: 7.0337e-05  eta: 0:24:04  time: 0.9673  data_time: 0.0046  memory: 2158  loss: 0.7189  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7189
2025/05/28 15:45:50 - mmengine - INFO - Epoch(train) [12][20/37]  base_lr: 7.0337e-04 lr: 7.0337e-05  eta: 0:23:53  time: 0.9679  data_time: 0.0050  memory: 2158  loss: 0.6923  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6923
2025/05/28 15:45:59 - mmengine - INFO - Epoch(train) [12][30/37]  base_lr: 7.0337e-04 lr: 7.0337e-05  eta: 0:23:41  time: 0.9644  data_time: 0.0037  memory: 2158  loss: 0.7768  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7768
2025/05/28 15:46:06 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:46:06 - mmengine - INFO - Epoch(train) [12][37/37]  base_lr: 7.0337e-04 lr: 7.0337e-05  eta: 0:23:34  time: 0.9672  data_time: 0.0034  memory: 2158  loss: 0.7549  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7549
2025/05/28 15:46:06 - mmengine - INFO - Saving checkpoint at 12 epochs
2025/05/28 15:46:15 - mmengine - INFO - Epoch(val) [12][10/10]    eta: 0:00:00  time: 0.3480  data_time: 0.0043  memory: 798  
2025/05/28 15:46:15 - mmengine - INFO - Epoch(val) [12][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0041  time: 0.3249
2025/05/28 15:46:24 - mmengine - INFO - Epoch(train) [13][10/37]  base_lr: 6.5451e-04 lr: 6.5451e-05  eta: 0:23:22  time: 0.9675  data_time: 0.0047  memory: 2158  loss: 0.7217  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7217
2025/05/28 15:46:34 - mmengine - INFO - Epoch(train) [13][20/37]  base_lr: 6.5451e-04 lr: 6.5451e-05  eta: 0:23:11  time: 0.9649  data_time: 0.0047  memory: 2158  loss: 0.6934  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6934
2025/05/28 15:46:43 - mmengine - INFO - Epoch(train) [13][30/37]  base_lr: 6.5451e-04 lr: 6.5451e-05  eta: 0:23:00  time: 0.9641  data_time: 0.0033  memory: 2158  loss: 0.7387  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7387
2025/05/28 15:46:50 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:46:50 - mmengine - INFO - Epoch(train) [13][37/37]  base_lr: 6.5451e-04 lr: 6.5451e-05  eta: 0:22:52  time: 0.9639  data_time: 0.0033  memory: 2158  loss: 0.7515  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7515
2025/05/28 15:46:50 - mmengine - INFO - Saving checkpoint at 13 epochs
2025/05/28 15:46:58 - mmengine - INFO - Epoch(val) [13][10/10]    eta: 0:00:00  time: 0.3405  data_time: 0.0043  memory: 798  
2025/05/28 15:46:58 - mmengine - INFO - Epoch(val) [13][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0041  time: 0.3277
2025/05/28 15:47:08 - mmengine - INFO - Epoch(train) [14][10/37]  base_lr: 6.0396e-04 lr: 6.0396e-05  eta: 0:22:41  time: 0.9661  data_time: 0.0048  memory: 2158  loss: 0.7206  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7206
2025/05/28 15:47:18 - mmengine - INFO - Epoch(train) [14][20/37]  base_lr: 6.0396e-04 lr: 6.0396e-05  eta: 0:22:30  time: 0.9652  data_time: 0.0049  memory: 2158  loss: 0.6966  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6966
2025/05/28 15:47:27 - mmengine - INFO - Epoch(train) [14][30/37]  base_lr: 6.0396e-04 lr: 6.0396e-05  eta: 0:22:19  time: 0.9625  data_time: 0.0034  memory: 2158  loss: 0.7215  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7215
2025/05/28 15:47:34 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:47:34 - mmengine - INFO - Epoch(train) [14][37/37]  base_lr: 6.0396e-04 lr: 6.0396e-05  eta: 0:22:11  time: 0.9630  data_time: 0.0034  memory: 2158  loss: 0.8033  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8033
2025/05/28 15:47:34 - mmengine - INFO - Saving checkpoint at 14 epochs
2025/05/28 15:47:42 - mmengine - INFO - Epoch(val) [14][10/10]    eta: 0:00:00  time: 0.3410  data_time: 0.0045  memory: 798  
2025/05/28 15:47:42 - mmengine - INFO - Epoch(val) [14][10/10]    acc/top1: 0.4474  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0045  time: 0.3257
2025/05/28 15:47:52 - mmengine - INFO - Epoch(train) [15][10/37]  base_lr: 5.5226e-04 lr: 5.5226e-05  eta: 0:22:00  time: 0.9646  data_time: 0.0048  memory: 2158  loss: 0.8699  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8699
2025/05/28 15:48:02 - mmengine - INFO - Epoch(train) [15][20/37]  base_lr: 5.5226e-04 lr: 5.5226e-05  eta: 0:21:50  time: 0.9656  data_time: 0.0047  memory: 2158  loss: 0.7597  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7597
2025/05/28 15:48:11 - mmengine - INFO - Epoch(train) [15][30/37]  base_lr: 5.5226e-04 lr: 5.5226e-05  eta: 0:21:39  time: 0.9659  data_time: 0.0033  memory: 2158  loss: 0.6910  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6910
2025/05/28 15:48:18 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:48:18 - mmengine - INFO - Epoch(train) [15][37/37]  base_lr: 5.5226e-04 lr: 5.5226e-05  eta: 0:21:31  time: 0.9662  data_time: 0.0034  memory: 2158  loss: 0.7171  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7171
2025/05/28 15:48:18 - mmengine - INFO - Saving checkpoint at 15 epochs
2025/05/28 15:48:27 - mmengine - INFO - Epoch(val) [15][10/10]    eta: 0:00:00  time: 0.3401  data_time: 0.0044  memory: 798  
2025/05/28 15:48:27 - mmengine - INFO - Epoch(val) [15][10/10]    acc/top1: 0.4474  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0037  time: 0.3260
2025/05/28 15:48:36 - mmengine - INFO - Epoch(train) [16][10/37]  base_lr: 5.0000e-04 lr: 5.0000e-05  eta: 0:21:21  time: 0.9661  data_time: 0.0050  memory: 2158  loss: 0.8267  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8267
2025/05/28 15:48:46 - mmengine - INFO - Epoch(train) [16][20/37]  base_lr: 5.0000e-04 lr: 5.0000e-05  eta: 0:21:10  time: 0.9658  data_time: 0.0050  memory: 2158  loss: 0.7594  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7594
2025/05/28 15:48:56 - mmengine - INFO - Epoch(train) [16][30/37]  base_lr: 5.0000e-04 lr: 5.0000e-05  eta: 0:20:59  time: 0.9654  data_time: 0.0036  memory: 2158  loss: 0.7088  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7088
2025/05/28 15:49:02 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:49:02 - mmengine - INFO - Epoch(train) [16][37/37]  base_lr: 5.0000e-04 lr: 5.0000e-05  eta: 0:20:52  time: 0.9669  data_time: 0.0036  memory: 2158  loss: 0.6874  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6874
2025/05/28 15:49:02 - mmengine - INFO - Saving checkpoint at 16 epochs
2025/05/28 15:49:11 - mmengine - INFO - Epoch(val) [16][10/10]    eta: 0:00:00  time: 0.3400  data_time: 0.0044  memory: 798  
2025/05/28 15:49:11 - mmengine - INFO - Epoch(val) [16][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0045  time: 0.3255
2025/05/28 15:49:20 - mmengine - INFO - Epoch(train) [17][10/37]  base_lr: 4.4774e-04 lr: 4.4774e-05  eta: 0:20:41  time: 0.9655  data_time: 0.0051  memory: 2158  loss: 0.7075  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7075
2025/05/28 15:49:30 - mmengine - INFO - Epoch(train) [17][20/37]  base_lr: 4.4774e-04 lr: 4.4774e-05  eta: 0:20:31  time: 0.9631  data_time: 0.0051  memory: 2158  loss: 0.7335  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7335
2025/05/28 15:49:39 - mmengine - INFO - Epoch(train) [17][30/37]  base_lr: 4.4774e-04 lr: 4.4774e-05  eta: 0:20:20  time: 0.9628  data_time: 0.0034  memory: 2158  loss: 0.7109  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7109
2025/05/28 15:49:46 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:49:46 - mmengine - INFO - Epoch(train) [17][37/37]  base_lr: 4.4774e-04 lr: 4.4774e-05  eta: 0:20:13  time: 0.9636  data_time: 0.0033  memory: 2158  loss: 0.7308  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7308
2025/05/28 15:49:46 - mmengine - INFO - Saving checkpoint at 17 epochs
2025/05/28 15:49:55 - mmengine - INFO - Epoch(val) [17][10/10]    eta: 0:00:00  time: 0.3462  data_time: 0.0044  memory: 798  
2025/05/28 15:49:55 - mmengine - INFO - Epoch(val) [17][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0040  time: 0.3375
2025/05/28 15:50:05 - mmengine - INFO - Epoch(train) [18][10/37]  base_lr: 3.9604e-04 lr: 3.9604e-05  eta: 0:20:02  time: 0.9669  data_time: 0.0049  memory: 2158  loss: 0.6666  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6666
2025/05/28 15:50:14 - mmengine - INFO - Epoch(train) [18][20/37]  base_lr: 3.9604e-04 lr: 3.9604e-05  eta: 0:19:52  time: 0.9675  data_time: 0.0051  memory: 2158  loss: 0.6822  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.6822
2025/05/28 15:50:24 - mmengine - INFO - Epoch(train) [18][30/37]  base_lr: 3.9604e-04 lr: 3.9604e-05  eta: 0:19:42  time: 0.9647  data_time: 0.0037  memory: 2158  loss: 0.7124  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7124
2025/05/28 15:50:31 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:50:31 - mmengine - INFO - Epoch(train) [18][37/37]  base_lr: 3.9604e-04 lr: 3.9604e-05  eta: 0:19:34  time: 0.9646  data_time: 0.0036  memory: 2158  loss: 0.7172  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7172
2025/05/28 15:50:31 - mmengine - INFO - Saving checkpoint at 18 epochs
2025/05/28 15:50:39 - mmengine - INFO - Epoch(val) [18][10/10]    eta: 0:00:00  time: 0.3540  data_time: 0.0041  memory: 798  
2025/05/28 15:50:39 - mmengine - INFO - Epoch(val) [18][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0038  time: 0.3395
2025/05/28 15:50:49 - mmengine - INFO - Epoch(train) [19][10/37]  base_lr: 3.4549e-04 lr: 3.4549e-05  eta: 0:19:24  time: 0.9673  data_time: 0.0050  memory: 2158  loss: 0.7152  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7152
2025/05/28 15:50:58 - mmengine - INFO - Epoch(train) [19][20/37]  base_lr: 3.4549e-04 lr: 3.4549e-05  eta: 0:19:14  time: 0.9656  data_time: 0.0048  memory: 2158  loss: 0.7535  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7535
2025/05/28 15:51:08 - mmengine - INFO - Epoch(train) [19][30/37]  base_lr: 3.4549e-04 lr: 3.4549e-05  eta: 0:19:03  time: 0.9640  data_time: 0.0035  memory: 2158  loss: 0.7678  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7678
2025/05/28 15:51:15 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:51:15 - mmengine - INFO - Epoch(train) [19][37/37]  base_lr: 3.4549e-04 lr: 3.4549e-05  eta: 0:18:56  time: 0.9644  data_time: 0.0035  memory: 2158  loss: 0.7506  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7506
2025/05/28 15:51:15 - mmengine - INFO - Saving checkpoint at 19 epochs
2025/05/28 15:51:23 - mmengine - INFO - Epoch(val) [19][10/10]    eta: 0:00:00  time: 0.3472  data_time: 0.0042  memory: 798  
2025/05/28 15:51:23 - mmengine - INFO - Epoch(val) [19][10/10]    acc/top1: 0.5263  acc/top5: 1.0000  acc/mean1: 0.4818  data_time: 0.0041  time: 0.3251
2025/05/28 15:51:33 - mmengine - INFO - Epoch(train) [20][10/37]  base_lr: 2.9663e-04 lr: 2.9663e-05  eta: 0:18:46  time: 0.9658  data_time: 0.0050  memory: 2158  loss: 0.7120  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7120
2025/05/28 15:51:42 - mmengine - INFO - Epoch(train) [20][20/37]  base_lr: 2.9663e-04 lr: 2.9663e-05  eta: 0:18:35  time: 0.9655  data_time: 0.0052  memory: 2158  loss: 0.6898  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6898
2025/05/28 15:51:52 - mmengine - INFO - Epoch(train) [20][30/37]  base_lr: 2.9663e-04 lr: 2.9663e-05  eta: 0:18:25  time: 0.9637  data_time: 0.0036  memory: 2158  loss: 0.6879  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6879
2025/05/28 15:51:59 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:51:59 - mmengine - INFO - Epoch(train) [20][37/37]  base_lr: 2.9663e-04 lr: 2.9663e-05  eta: 0:18:18  time: 0.9643  data_time: 0.0036  memory: 2158  loss: 0.7281  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7281
2025/05/28 15:51:59 - mmengine - INFO - Saving checkpoint at 20 epochs
2025/05/28 15:52:08 - mmengine - INFO - Epoch(val) [20][10/10]    eta: 0:00:00  time: 0.3489  data_time: 0.0045  memory: 798  
2025/05/28 15:52:08 - mmengine - INFO - Epoch(val) [20][10/10]    acc/top1: 0.5263  acc/top5: 1.0000  acc/mean1: 0.4762  data_time: 0.0043  time: 0.3427
2025/05/28 15:52:18 - mmengine - INFO - Epoch(train) [21][10/37]  base_lr: 2.5000e-04 lr: 2.5000e-05  eta: 0:18:08  time: 0.9661  data_time: 0.0051  memory: 2158  loss: 0.7149  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7149
2025/05/28 15:52:27 - mmengine - INFO - Epoch(train) [21][20/37]  base_lr: 2.5000e-04 lr: 2.5000e-05  eta: 0:17:57  time: 0.9658  data_time: 0.0051  memory: 2158  loss: 0.6961  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6961
2025/05/28 15:52:37 - mmengine - INFO - Epoch(train) [21][30/37]  base_lr: 2.5000e-04 lr: 2.5000e-05  eta: 0:17:47  time: 0.9646  data_time: 0.0035  memory: 2158  loss: 0.6978  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6978
2025/05/28 15:52:44 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:52:44 - mmengine - INFO - Epoch(train) [21][37/37]  base_lr: 2.5000e-04 lr: 2.5000e-05  eta: 0:17:40  time: 0.9652  data_time: 0.0034  memory: 2158  loss: 0.7075  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7075
2025/05/28 15:52:44 - mmengine - INFO - Saving checkpoint at 21 epochs
2025/05/28 15:52:52 - mmengine - INFO - Epoch(val) [21][10/10]    eta: 0:00:00  time: 0.3490  data_time: 0.0046  memory: 798  
2025/05/28 15:52:52 - mmengine - INFO - Epoch(val) [21][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0043  time: 0.3253
2025/05/28 15:53:02 - mmengine - INFO - Epoch(train) [22][10/37]  base_lr: 2.0611e-04 lr: 2.0611e-05  eta: 0:17:30  time: 0.9669  data_time: 0.0047  memory: 2158  loss: 0.7510  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.7510
2025/05/28 15:53:11 - mmengine - INFO - Epoch(train) [22][20/37]  base_lr: 2.0611e-04 lr: 2.0611e-05  eta: 0:17:20  time: 0.9662  data_time: 0.0051  memory: 2158  loss: 0.7344  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7344
2025/05/28 15:53:21 - mmengine - INFO - Epoch(train) [22][30/37]  base_lr: 2.0611e-04 lr: 2.0611e-05  eta: 0:17:09  time: 0.9639  data_time: 0.0039  memory: 2158  loss: 0.6679  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6679
2025/05/28 15:53:28 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:53:28 - mmengine - INFO - Epoch(train) [22][37/37]  base_lr: 2.0611e-04 lr: 2.0611e-05  eta: 0:17:02  time: 0.9632  data_time: 0.0035  memory: 2158  loss: 0.6735  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6735
2025/05/28 15:53:28 - mmengine - INFO - Saving checkpoint at 22 epochs
2025/05/28 15:53:37 - mmengine - INFO - Epoch(val) [22][10/10]    eta: 0:00:00  time: 0.3488  data_time: 0.0045  memory: 798  
2025/05/28 15:53:37 - mmengine - INFO - Epoch(val) [22][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0042  time: 0.3423
2025/05/28 15:53:46 - mmengine - INFO - Epoch(train) [23][10/37]  base_lr: 1.6543e-04 lr: 1.6543e-05  eta: 0:16:52  time: 0.9647  data_time: 0.0046  memory: 2158  loss: 0.7029  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7029
2025/05/28 15:53:56 - mmengine - INFO - Epoch(train) [23][20/37]  base_lr: 1.6543e-04 lr: 1.6543e-05  eta: 0:16:42  time: 0.9658  data_time: 0.0046  memory: 2158  loss: 0.6826  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6826
2025/05/28 15:54:06 - mmengine - INFO - Epoch(train) [23][30/37]  base_lr: 1.6543e-04 lr: 1.6543e-05  eta: 0:16:32  time: 0.9660  data_time: 0.0034  memory: 2158  loss: 0.6651  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6651
2025/05/28 15:54:12 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:54:12 - mmengine - INFO - Epoch(train) [23][37/37]  base_lr: 1.6543e-04 lr: 1.6543e-05  eta: 0:16:25  time: 0.9656  data_time: 0.0033  memory: 2158  loss: 0.6751  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6751
2025/05/28 15:54:12 - mmengine - INFO - Saving checkpoint at 23 epochs
2025/05/28 15:54:22 - mmengine - INFO - Epoch(val) [23][10/10]    eta: 0:00:00  time: 0.3486  data_time: 0.0043  memory: 798  
2025/05/28 15:54:22 - mmengine - INFO - Epoch(val) [23][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0040  time: 0.3251
2025/05/28 15:54:32 - mmengine - INFO - Epoch(train) [24][10/37]  base_lr: 1.2843e-04 lr: 1.2843e-05  eta: 0:16:15  time: 0.9663  data_time: 0.0048  memory: 2158  loss: 0.6731  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6731
2025/05/28 15:54:42 - mmengine - INFO - Epoch(train) [24][20/37]  base_lr: 1.2843e-04 lr: 1.2843e-05  eta: 0:16:05  time: 0.9665  data_time: 0.0047  memory: 2158  loss: 0.6965  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6965
2025/05/28 15:54:51 - mmengine - INFO - Epoch(train) [24][30/37]  base_lr: 1.2843e-04 lr: 1.2843e-05  eta: 0:15:55  time: 0.9652  data_time: 0.0034  memory: 2158  loss: 0.6842  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6842
2025/05/28 15:54:58 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:54:58 - mmengine - INFO - Epoch(train) [24][37/37]  base_lr: 1.2843e-04 lr: 1.2843e-05  eta: 0:15:48  time: 0.9643  data_time: 0.0036  memory: 2158  loss: 0.6802  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6802
2025/05/28 15:54:58 - mmengine - INFO - Saving checkpoint at 24 epochs
2025/05/28 15:55:06 - mmengine - INFO - Epoch(val) [24][10/10]    eta: 0:00:00  time: 0.3448  data_time: 0.0044  memory: 798  
2025/05/28 15:55:06 - mmengine - INFO - Epoch(val) [24][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0045  time: 0.3353
2025/05/28 15:55:16 - mmengine - INFO - Epoch(train) [25][10/37]  base_lr: 9.5492e-05 lr: 9.5492e-06  eta: 0:15:37  time: 0.9648  data_time: 0.0049  memory: 2158  loss: 0.6733  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6733
2025/05/28 15:55:26 - mmengine - INFO - Epoch(train) [25][20/37]  base_lr: 9.5492e-05 lr: 9.5492e-06  eta: 0:15:27  time: 0.9638  data_time: 0.0046  memory: 2158  loss: 0.6724  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.6724
2025/05/28 15:55:35 - mmengine - INFO - Epoch(train) [25][30/37]  base_lr: 9.5492e-05 lr: 9.5492e-06  eta: 0:15:17  time: 0.9622  data_time: 0.0033  memory: 2158  loss: 0.6851  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6851
2025/05/28 15:55:42 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:55:42 - mmengine - INFO - Epoch(train) [25][37/37]  base_lr: 9.5492e-05 lr: 9.5492e-06  eta: 0:15:10  time: 0.9620  data_time: 0.0033  memory: 2158  loss: 0.6846  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6846
2025/05/28 15:55:42 - mmengine - INFO - Saving checkpoint at 25 epochs
2025/05/28 15:55:50 - mmengine - INFO - Epoch(val) [25][10/10]    eta: 0:00:00  time: 0.3446  data_time: 0.0044  memory: 798  
2025/05/28 15:55:50 - mmengine - INFO - Epoch(val) [25][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0039  time: 0.3247
2025/05/28 15:56:00 - mmengine - INFO - Epoch(train) [26][10/37]  base_lr: 6.6987e-05 lr: 6.6987e-06  eta: 0:15:00  time: 0.9633  data_time: 0.0046  memory: 2158  loss: 0.6732  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6732
2025/05/28 15:56:09 - mmengine - INFO - Epoch(train) [26][20/37]  base_lr: 6.6987e-05 lr: 6.6987e-06  eta: 0:14:50  time: 0.9658  data_time: 0.0047  memory: 2158  loss: 0.6587  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6587
2025/05/28 15:56:19 - mmengine - INFO - Epoch(train) [26][30/37]  base_lr: 6.6987e-05 lr: 6.6987e-06  eta: 0:14:40  time: 0.9649  data_time: 0.0033  memory: 2158  loss: 0.6502  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6502
2025/05/28 15:56:26 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:56:26 - mmengine - INFO - Epoch(train) [26][37/37]  base_lr: 6.6987e-05 lr: 6.6987e-06  eta: 0:14:33  time: 0.9619  data_time: 0.0035  memory: 2158  loss: 0.6803  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6803
2025/05/28 15:56:26 - mmengine - INFO - Saving checkpoint at 26 epochs
2025/05/28 15:56:34 - mmengine - INFO - Epoch(val) [26][10/10]    eta: 0:00:00  time: 0.3482  data_time: 0.0043  memory: 798  
2025/05/28 15:56:34 - mmengine - INFO - Epoch(val) [26][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0043  time: 0.3419
2025/05/28 15:56:44 - mmengine - INFO - Epoch(train) [27][10/37]  base_lr: 4.3227e-05 lr: 4.3227e-06  eta: 0:14:23  time: 0.9634  data_time: 0.0049  memory: 2158  loss: 0.6815  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6815
2025/05/28 15:56:53 - mmengine - INFO - Epoch(train) [27][20/37]  base_lr: 4.3227e-05 lr: 4.3227e-06  eta: 0:14:13  time: 0.9641  data_time: 0.0047  memory: 2158  loss: 0.7162  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7162
2025/05/28 15:57:03 - mmengine - INFO - Epoch(train) [27][30/37]  base_lr: 4.3227e-05 lr: 4.3227e-06  eta: 0:14:03  time: 0.9649  data_time: 0.0033  memory: 2158  loss: 0.7421  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7421
2025/05/28 15:57:10 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:57:10 - mmengine - INFO - Epoch(train) [27][37/37]  base_lr: 4.3227e-05 lr: 4.3227e-06  eta: 0:13:56  time: 0.9667  data_time: 0.0034  memory: 2158  loss: 0.7371  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7371
2025/05/28 15:57:10 - mmengine - INFO - Saving checkpoint at 27 epochs
2025/05/28 15:57:18 - mmengine - INFO - Epoch(val) [27][10/10]    eta: 0:00:00  time: 0.3484  data_time: 0.0044  memory: 798  
2025/05/28 15:57:18 - mmengine - INFO - Epoch(val) [27][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0040  time: 0.3249
2025/05/28 15:57:19 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:57:28 - mmengine - INFO - Epoch(train) [28][10/37]  base_lr: 2.4472e-05 lr: 2.4472e-06  eta: 0:13:46  time: 0.9690  data_time: 0.0050  memory: 2158  loss: 0.6465  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6465
2025/05/28 15:57:37 - mmengine - INFO - Epoch(train) [28][20/37]  base_lr: 2.4472e-05 lr: 2.4472e-06  eta: 0:13:36  time: 0.9657  data_time: 0.0051  memory: 2158  loss: 0.6790  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6790
2025/05/28 15:57:47 - mmengine - INFO - Epoch(train) [28][30/37]  base_lr: 2.4472e-05 lr: 2.4472e-06  eta: 0:13:26  time: 0.9639  data_time: 0.0035  memory: 2158  loss: 0.7171  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7171
2025/05/28 15:57:54 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:57:54 - mmengine - INFO - Epoch(train) [28][37/37]  base_lr: 2.4472e-05 lr: 2.4472e-06  eta: 0:13:19  time: 0.9657  data_time: 0.0035  memory: 2158  loss: 0.6871  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6871
2025/05/28 15:57:54 - mmengine - INFO - Saving checkpoint at 28 epochs
2025/05/28 15:58:02 - mmengine - INFO - Epoch(val) [28][10/10]    eta: 0:00:00  time: 0.3470  data_time: 0.0044  memory: 798  
2025/05/28 15:58:02 - mmengine - INFO - Epoch(val) [28][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0043  time: 0.3394
2025/05/28 15:58:12 - mmengine - INFO - Epoch(train) [29][10/37]  base_lr: 1.0926e-05 lr: 1.0926e-06  eta: 0:13:09  time: 0.9686  data_time: 0.0050  memory: 2158  loss: 0.6510  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6510
2025/05/28 15:58:21 - mmengine - INFO - Epoch(train) [29][20/37]  base_lr: 1.0926e-05 lr: 1.0926e-06  eta: 0:12:59  time: 0.9661  data_time: 0.0053  memory: 2158  loss: 0.6741  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6741
2025/05/28 15:58:31 - mmengine - INFO - Epoch(train) [29][30/37]  base_lr: 1.0926e-05 lr: 1.0926e-06  eta: 0:12:49  time: 0.9632  data_time: 0.0038  memory: 2158  loss: 0.6469  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6469
2025/05/28 15:58:38 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:58:38 - mmengine - INFO - Epoch(train) [29][37/37]  base_lr: 1.0926e-05 lr: 1.0926e-06  eta: 0:12:42  time: 0.9648  data_time: 0.0034  memory: 2158  loss: 0.6690  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6690
2025/05/28 15:58:38 - mmengine - INFO - Saving checkpoint at 29 epochs
2025/05/28 15:58:47 - mmengine - INFO - Epoch(val) [29][10/10]    eta: 0:00:00  time: 0.3537  data_time: 0.0046  memory: 798  
2025/05/28 15:58:47 - mmengine - INFO - Epoch(val) [29][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0044  time: 0.3372
2025/05/28 15:58:56 - mmengine - INFO - Epoch(train) [30][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:12:33  time: 0.9660  data_time: 0.0049  memory: 2158  loss: 0.6631  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6631
2025/05/28 15:59:06 - mmengine - INFO - Epoch(train) [30][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:12:23  time: 0.9658  data_time: 0.0049  memory: 2158  loss: 0.7069  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7069
2025/05/28 15:59:16 - mmengine - INFO - Epoch(train) [30][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:12:13  time: 0.9652  data_time: 0.0036  memory: 2158  loss: 0.6914  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6914
2025/05/28 15:59:22 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 15:59:22 - mmengine - INFO - Epoch(train) [30][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:12:06  time: 0.9624  data_time: 0.0036  memory: 2158  loss: 0.6494  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6494
2025/05/28 15:59:22 - mmengine - INFO - Saving checkpoint at 30 epochs
2025/05/28 15:59:31 - mmengine - INFO - Epoch(val) [30][10/10]    eta: 0:00:00  time: 0.3457  data_time: 0.0044  memory: 798  
2025/05/28 15:59:31 - mmengine - INFO - Epoch(val) [30][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0040  time: 0.3248
2025/05/28 15:59:40 - mmengine - INFO - Epoch(train) [31][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:11:56  time: 0.9641  data_time: 0.0047  memory: 2158  loss: 0.6525  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6525
2025/05/28 15:59:50 - mmengine - INFO - Epoch(train) [31][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:11:46  time: 0.9658  data_time: 0.0047  memory: 2158  loss: 0.6632  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6632
2025/05/28 16:00:00 - mmengine - INFO - Epoch(train) [31][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:11:36  time: 0.9653  data_time: 0.0037  memory: 2158  loss: 0.6554  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6554
2025/05/28 16:00:07 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:00:07 - mmengine - INFO - Epoch(train) [31][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:11:29  time: 0.9664  data_time: 0.0037  memory: 2158  loss: 0.6967  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6967
2025/05/28 16:00:07 - mmengine - INFO - Saving checkpoint at 31 epochs
2025/05/28 16:00:15 - mmengine - INFO - Epoch(val) [31][10/10]    eta: 0:00:00  time: 0.3472  data_time: 0.0044  memory: 798  
2025/05/28 16:00:15 - mmengine - INFO - Epoch(val) [31][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0041  time: 0.3399
2025/05/28 16:00:25 - mmengine - INFO - Epoch(train) [32][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:11:19  time: 0.9670  data_time: 0.0049  memory: 2158  loss: 0.7336  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7336
2025/05/28 16:00:35 - mmengine - INFO - Epoch(train) [32][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:11:09  time: 0.9647  data_time: 0.0049  memory: 2158  loss: 0.7210  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7210
2025/05/28 16:00:44 - mmengine - INFO - Epoch(train) [32][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:10:59  time: 0.9631  data_time: 0.0034  memory: 2158  loss: 0.6787  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6787
2025/05/28 16:00:51 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:00:51 - mmengine - INFO - Epoch(train) [32][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:10:52  time: 0.9638  data_time: 0.0033  memory: 2158  loss: 0.6668  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6668
2025/05/28 16:00:51 - mmengine - INFO - Saving checkpoint at 32 epochs
2025/05/28 16:00:59 - mmengine - INFO - Epoch(val) [32][10/10]    eta: 0:00:00  time: 0.3476  data_time: 0.0049  memory: 798  
2025/05/28 16:00:59 - mmengine - INFO - Epoch(val) [32][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0050  time: 0.3256
2025/05/28 16:01:09 - mmengine - INFO - Epoch(train) [33][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:10:43  time: 0.9668  data_time: 0.0048  memory: 2158  loss: 0.6843  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6843
2025/05/28 16:01:19 - mmengine - INFO - Epoch(train) [33][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:10:33  time: 0.9661  data_time: 0.0050  memory: 2158  loss: 0.6552  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6552
2025/05/28 16:01:28 - mmengine - INFO - Epoch(train) [33][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:10:23  time: 0.9636  data_time: 0.0034  memory: 2158  loss: 0.6503  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6503
2025/05/28 16:01:35 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:01:35 - mmengine - INFO - Epoch(train) [33][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:10:16  time: 0.9632  data_time: 0.0032  memory: 2158  loss: 0.6746  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6746
2025/05/28 16:01:35 - mmengine - INFO - Saving checkpoint at 33 epochs
2025/05/28 16:01:43 - mmengine - INFO - Epoch(val) [33][10/10]    eta: 0:00:00  time: 0.3481  data_time: 0.0052  memory: 798  
2025/05/28 16:01:43 - mmengine - INFO - Epoch(val) [33][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0048  time: 0.3409
2025/05/28 16:01:53 - mmengine - INFO - Epoch(train) [34][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:10:06  time: 0.9632  data_time: 0.0046  memory: 2158  loss: 0.7115  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7115
2025/05/28 16:02:03 - mmengine - INFO - Epoch(train) [34][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:09:56  time: 0.9658  data_time: 0.0047  memory: 2158  loss: 0.7242  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7242
2025/05/28 16:02:12 - mmengine - INFO - Epoch(train) [34][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:09:46  time: 0.9661  data_time: 0.0036  memory: 2158  loss: 0.6668  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6668
2025/05/28 16:02:19 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:02:19 - mmengine - INFO - Epoch(train) [34][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:09:39  time: 0.9660  data_time: 0.0036  memory: 2158  loss: 0.6500  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6500
2025/05/28 16:02:19 - mmengine - INFO - Saving checkpoint at 34 epochs
2025/05/28 16:02:27 - mmengine - INFO - Epoch(val) [34][10/10]    eta: 0:00:00  time: 0.3478  data_time: 0.0047  memory: 798  
2025/05/28 16:02:27 - mmengine - INFO - Epoch(val) [34][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0042  time: 0.3251
2025/05/28 16:02:37 - mmengine - INFO - Epoch(train) [35][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:09:29  time: 0.9659  data_time: 0.0050  memory: 2158  loss: 0.6924  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6924
2025/05/28 16:02:47 - mmengine - INFO - Epoch(train) [35][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:09:20  time: 0.9651  data_time: 0.0049  memory: 2158  loss: 0.6898  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6898
2025/05/28 16:02:56 - mmengine - INFO - Epoch(train) [35][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:09:10  time: 0.9630  data_time: 0.0033  memory: 2158  loss: 0.6617  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6617
2025/05/28 16:03:03 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:03:03 - mmengine - INFO - Epoch(train) [35][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:09:03  time: 0.9651  data_time: 0.0033  memory: 2158  loss: 0.6433  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6433
2025/05/28 16:03:03 - mmengine - INFO - Saving checkpoint at 35 epochs
2025/05/28 16:03:12 - mmengine - INFO - Epoch(val) [35][10/10]    eta: 0:00:00  time: 0.3488  data_time: 0.0044  memory: 798  
2025/05/28 16:03:12 - mmengine - INFO - Epoch(val) [35][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0041  time: 0.3426
2025/05/28 16:03:22 - mmengine - INFO - Epoch(train) [36][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:08:53  time: 0.9665  data_time: 0.0044  memory: 2158  loss: 0.6500  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6500
2025/05/28 16:03:31 - mmengine - INFO - Epoch(train) [36][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:08:43  time: 0.9660  data_time: 0.0044  memory: 2158  loss: 0.6442  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6442
2025/05/28 16:03:41 - mmengine - INFO - Epoch(train) [36][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:08:33  time: 0.9650  data_time: 0.0033  memory: 2158  loss: 0.6778  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.6778
2025/05/28 16:03:48 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:03:48 - mmengine - INFO - Epoch(train) [36][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:08:26  time: 0.9692  data_time: 0.0034  memory: 2158  loss: 0.7056  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7056
2025/05/28 16:03:48 - mmengine - INFO - Saving checkpoint at 36 epochs
2025/05/28 16:03:56 - mmengine - INFO - Epoch(val) [36][10/10]    eta: 0:00:00  time: 0.3489  data_time: 0.0046  memory: 798  
2025/05/28 16:03:56 - mmengine - INFO - Epoch(val) [36][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0044  time: 0.3252
2025/05/28 16:04:06 - mmengine - INFO - Epoch(train) [37][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:08:17  time: 0.9728  data_time: 0.0050  memory: 2158  loss: 0.7025  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7025
2025/05/28 16:04:16 - mmengine - INFO - Epoch(train) [37][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:08:07  time: 0.9676  data_time: 0.0050  memory: 2158  loss: 0.6930  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6930
2025/05/28 16:04:25 - mmengine - INFO - Epoch(train) [37][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:07:57  time: 0.9644  data_time: 0.0035  memory: 2158  loss: 0.7107  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7107
2025/05/28 16:04:32 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:04:32 - mmengine - INFO - Epoch(train) [37][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:07:50  time: 0.9642  data_time: 0.0034  memory: 2158  loss: 0.7204  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7204
2025/05/28 16:04:32 - mmengine - INFO - Saving checkpoint at 37 epochs
2025/05/28 16:04:40 - mmengine - INFO - Epoch(val) [37][10/10]    eta: 0:00:00  time: 0.3438  data_time: 0.0049  memory: 798  
2025/05/28 16:04:40 - mmengine - INFO - Epoch(val) [37][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0048  time: 0.3334
2025/05/28 16:04:50 - mmengine - INFO - Epoch(train) [38][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:07:40  time: 0.9666  data_time: 0.0048  memory: 2158  loss: 0.6455  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6455
2025/05/28 16:05:00 - mmengine - INFO - Epoch(train) [38][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:07:30  time: 0.9658  data_time: 0.0048  memory: 2158  loss: 0.6849  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6849
2025/05/28 16:05:09 - mmengine - INFO - Epoch(train) [38][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:07:21  time: 0.9654  data_time: 0.0035  memory: 2158  loss: 0.7318  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7318
2025/05/28 16:05:16 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:05:16 - mmengine - INFO - Epoch(train) [38][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:07:14  time: 0.9656  data_time: 0.0034  memory: 2158  loss: 0.7054  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7054
2025/05/28 16:05:16 - mmengine - INFO - Saving checkpoint at 38 epochs
2025/05/28 16:05:25 - mmengine - INFO - Epoch(val) [38][10/10]    eta: 0:00:00  time: 0.3504  data_time: 0.0049  memory: 798  
2025/05/28 16:05:25 - mmengine - INFO - Epoch(val) [38][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0044  time: 0.3371
2025/05/28 16:05:35 - mmengine - INFO - Epoch(train) [39][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:07:04  time: 0.9646  data_time: 0.0049  memory: 2158  loss: 0.6402  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6402
2025/05/28 16:05:44 - mmengine - INFO - Epoch(train) [39][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:06:54  time: 0.9644  data_time: 0.0051  memory: 2158  loss: 0.6744  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6744
2025/05/28 16:05:54 - mmengine - INFO - Epoch(train) [39][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:06:44  time: 0.9633  data_time: 0.0036  memory: 2158  loss: 0.6864  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6864
2025/05/28 16:06:01 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:06:01 - mmengine - INFO - Epoch(train) [39][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:06:37  time: 0.9646  data_time: 0.0034  memory: 2158  loss: 0.6840  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6840
2025/05/28 16:06:01 - mmengine - INFO - Saving checkpoint at 39 epochs
2025/05/28 16:06:09 - mmengine - INFO - Epoch(val) [39][10/10]    eta: 0:00:00  time: 0.3459  data_time: 0.0048  memory: 798  
2025/05/28 16:06:09 - mmengine - INFO - Epoch(val) [39][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0046  time: 0.3252
2025/05/28 16:06:19 - mmengine - INFO - Epoch(train) [40][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:06:28  time: 0.9654  data_time: 0.0048  memory: 2158  loss: 0.6942  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6942
2025/05/28 16:06:28 - mmengine - INFO - Epoch(train) [40][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:06:18  time: 0.9647  data_time: 0.0048  memory: 2158  loss: 0.6886  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6886
2025/05/28 16:06:38 - mmengine - INFO - Epoch(train) [40][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:06:08  time: 0.9649  data_time: 0.0035  memory: 2158  loss: 0.7003  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7003
2025/05/28 16:06:45 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:06:45 - mmengine - INFO - Epoch(train) [40][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:06:01  time: 0.9650  data_time: 0.0035  memory: 2158  loss: 0.6584  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6584
2025/05/28 16:06:45 - mmengine - INFO - Saving checkpoint at 40 epochs
2025/05/28 16:06:53 - mmengine - INFO - Epoch(val) [40][10/10]    eta: 0:00:00  time: 0.3431  data_time: 0.0048  memory: 798  
2025/05/28 16:06:53 - mmengine - INFO - Epoch(val) [40][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0045  time: 0.3320
2025/05/28 16:07:03 - mmengine - INFO - Epoch(train) [41][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:05:51  time: 0.9668  data_time: 0.0051  memory: 2158  loss: 0.6239  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6239
2025/05/28 16:07:12 - mmengine - INFO - Epoch(train) [41][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:05:42  time: 0.9640  data_time: 0.0050  memory: 2158  loss: 0.6708  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6708
2025/05/28 16:07:22 - mmengine - INFO - Epoch(train) [41][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:05:32  time: 0.9614  data_time: 0.0034  memory: 2158  loss: 0.7470  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7470
2025/05/28 16:07:29 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:07:29 - mmengine - INFO - Epoch(train) [41][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:05:25  time: 0.9631  data_time: 0.0035  memory: 2158  loss: 0.6900  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6900
2025/05/28 16:07:29 - mmengine - INFO - Saving checkpoint at 41 epochs
2025/05/28 16:07:37 - mmengine - INFO - Epoch(val) [41][10/10]    eta: 0:00:00  time: 0.3431  data_time: 0.0045  memory: 798  
2025/05/28 16:07:37 - mmengine - INFO - Epoch(val) [41][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0041  time: 0.3250
2025/05/28 16:07:47 - mmengine - INFO - Epoch(train) [42][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:05:15  time: 0.9653  data_time: 0.0051  memory: 2158  loss: 0.6209  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6209
2025/05/28 16:07:56 - mmengine - INFO - Epoch(train) [42][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:05:05  time: 0.9645  data_time: 0.0050  memory: 2158  loss: 0.6497  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6497
2025/05/28 16:08:06 - mmengine - INFO - Epoch(train) [42][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:04:55  time: 0.9647  data_time: 0.0034  memory: 2158  loss: 0.6732  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6732
2025/05/28 16:08:13 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:08:13 - mmengine - INFO - Epoch(train) [42][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:04:49  time: 0.9652  data_time: 0.0033  memory: 2158  loss: 0.6948  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6948
2025/05/28 16:08:13 - mmengine - INFO - Saving checkpoint at 42 epochs
2025/05/28 16:08:21 - mmengine - INFO - Epoch(val) [42][10/10]    eta: 0:00:00  time: 0.3435  data_time: 0.0045  memory: 798  
2025/05/28 16:08:21 - mmengine - INFO - Epoch(val) [42][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0045  time: 0.3329
2025/05/28 16:08:31 - mmengine - INFO - Epoch(train) [43][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:04:39  time: 0.9645  data_time: 0.0049  memory: 2158  loss: 0.7097  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7097
2025/05/28 16:08:41 - mmengine - INFO - Epoch(train) [43][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:04:29  time: 0.9650  data_time: 0.0049  memory: 2158  loss: 0.6795  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6795
2025/05/28 16:08:50 - mmengine - INFO - Epoch(train) [43][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:04:19  time: 0.9639  data_time: 0.0033  memory: 2158  loss: 0.6682  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6682
2025/05/28 16:08:57 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:08:57 - mmengine - INFO - Epoch(train) [43][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:04:12  time: 0.9624  data_time: 0.0034  memory: 2158  loss: 0.6779  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6779
2025/05/28 16:08:57 - mmengine - INFO - Saving checkpoint at 43 epochs
2025/05/28 16:09:05 - mmengine - INFO - Epoch(val) [43][10/10]    eta: 0:00:00  time: 0.3436  data_time: 0.0047  memory: 798  
2025/05/28 16:09:05 - mmengine - INFO - Epoch(val) [43][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0045  time: 0.3254
2025/05/28 16:09:15 - mmengine - INFO - Epoch(train) [44][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:04:03  time: 0.9644  data_time: 0.0050  memory: 2158  loss: 0.6735  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6735
2025/05/28 16:09:25 - mmengine - INFO - Epoch(train) [44][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:03:53  time: 0.9666  data_time: 0.0050  memory: 2158  loss: 0.6578  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6578
2025/05/28 16:09:34 - mmengine - INFO - Epoch(train) [44][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:03:43  time: 0.9648  data_time: 0.0035  memory: 2158  loss: 0.6844  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.6844
2025/05/28 16:09:41 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:09:41 - mmengine - INFO - Epoch(train) [44][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:03:36  time: 0.9634  data_time: 0.0034  memory: 2158  loss: 0.7130  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7130
2025/05/28 16:09:41 - mmengine - INFO - Saving checkpoint at 44 epochs
2025/05/28 16:09:50 - mmengine - INFO - Epoch(val) [44][10/10]    eta: 0:00:00  time: 0.3470  data_time: 0.0046  memory: 798  
2025/05/28 16:09:50 - mmengine - INFO - Epoch(val) [44][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0041  time: 0.3389
2025/05/28 16:10:00 - mmengine - INFO - Epoch(train) [45][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:03:26  time: 0.9670  data_time: 0.0053  memory: 2158  loss: 0.6895  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6895
2025/05/28 16:10:09 - mmengine - INFO - Epoch(train) [45][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:03:17  time: 0.9683  data_time: 0.0053  memory: 2158  loss: 0.6660  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6660
2025/05/28 16:10:19 - mmengine - INFO - Epoch(train) [45][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:03:07  time: 0.9652  data_time: 0.0037  memory: 2158  loss: 0.6442  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6442
2025/05/28 16:10:26 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:10:26 - mmengine - INFO - Epoch(train) [45][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:03:00  time: 0.9644  data_time: 0.0037  memory: 2158  loss: 0.6814  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6814
2025/05/28 16:10:26 - mmengine - INFO - Saving checkpoint at 45 epochs
2025/05/28 16:10:35 - mmengine - INFO - Epoch(val) [45][10/10]    eta: 0:00:00  time: 0.3524  data_time: 0.0043  memory: 798  
2025/05/28 16:10:35 - mmengine - INFO - Epoch(val) [45][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0041  time: 0.3352
2025/05/28 16:10:44 - mmengine - INFO - Epoch(train) [46][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:02:50  time: 0.9659  data_time: 0.0050  memory: 2158  loss: 0.7100  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7100
2025/05/28 16:10:54 - mmengine - INFO - Epoch(train) [46][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:02:41  time: 0.9653  data_time: 0.0050  memory: 2158  loss: 0.6511  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6511
2025/05/28 16:11:04 - mmengine - INFO - Epoch(train) [46][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:02:31  time: 0.9654  data_time: 0.0035  memory: 2158  loss: 0.6733  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6733
2025/05/28 16:11:10 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:11:10 - mmengine - INFO - Epoch(train) [46][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:02:24  time: 0.9650  data_time: 0.0034  memory: 2158  loss: 0.7100  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7100
2025/05/28 16:11:10 - mmengine - INFO - Saving checkpoint at 46 epochs
2025/05/28 16:11:19 - mmengine - INFO - Epoch(val) [46][10/10]    eta: 0:00:00  time: 0.3448  data_time: 0.0045  memory: 798  
2025/05/28 16:11:19 - mmengine - INFO - Epoch(val) [46][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0045  time: 0.3252
2025/05/28 16:11:28 - mmengine - INFO - Epoch(train) [47][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:02:14  time: 0.9637  data_time: 0.0049  memory: 2158  loss: 0.7328  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.7328
2025/05/28 16:11:38 - mmengine - INFO - Epoch(train) [47][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:02:04  time: 0.9634  data_time: 0.0051  memory: 2158  loss: 0.6961  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6961
2025/05/28 16:11:48 - mmengine - INFO - Epoch(train) [47][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:01:55  time: 0.9629  data_time: 0.0035  memory: 2158  loss: 0.6776  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6776
2025/05/28 16:11:54 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:11:54 - mmengine - INFO - Epoch(train) [47][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:01:48  time: 0.9631  data_time: 0.0033  memory: 2158  loss: 0.6555  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6555
2025/05/28 16:11:54 - mmengine - INFO - Saving checkpoint at 47 epochs
2025/05/28 16:12:03 - mmengine - INFO - Epoch(val) [47][10/10]    eta: 0:00:00  time: 0.3464  data_time: 0.0046  memory: 798  
2025/05/28 16:12:03 - mmengine - INFO - Epoch(val) [47][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0042  time: 0.3381
2025/05/28 16:12:12 - mmengine - INFO - Epoch(train) [48][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:01:38  time: 0.9652  data_time: 0.0050  memory: 2158  loss: 0.6204  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6204
2025/05/28 16:12:22 - mmengine - INFO - Epoch(train) [48][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:01:28  time: 0.9655  data_time: 0.0051  memory: 2158  loss: 0.6541  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6541
2025/05/28 16:12:32 - mmengine - INFO - Epoch(train) [48][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:01:19  time: 0.9642  data_time: 0.0034  memory: 2158  loss: 0.6891  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6891
2025/05/28 16:12:38 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:12:38 - mmengine - INFO - Epoch(train) [48][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:01:12  time: 0.9645  data_time: 0.0037  memory: 2158  loss: 0.6868  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6868
2025/05/28 16:12:38 - mmengine - INFO - Saving checkpoint at 48 epochs
2025/05/28 16:12:47 - mmengine - INFO - Epoch(val) [48][10/10]    eta: 0:00:00  time: 0.3462  data_time: 0.0044  memory: 798  
2025/05/28 16:12:47 - mmengine - INFO - Epoch(val) [48][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0041  time: 0.3248
2025/05/28 16:12:56 - mmengine - INFO - Epoch(train) [49][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:01:02  time: 0.9663  data_time: 0.0054  memory: 2158  loss: 0.6523  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6523
2025/05/28 16:13:06 - mmengine - INFO - Epoch(train) [49][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:00:52  time: 0.9665  data_time: 0.0051  memory: 2158  loss: 0.6519  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6519
2025/05/28 16:13:16 - mmengine - INFO - Epoch(train) [49][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:00:42  time: 0.9643  data_time: 0.0036  memory: 2158  loss: 0.6693  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6693
2025/05/28 16:13:23 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:13:23 - mmengine - INFO - Epoch(train) [49][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:00:36  time: 0.9620  data_time: 0.0037  memory: 2158  loss: 0.7182  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7182
2025/05/28 16:13:23 - mmengine - INFO - Saving checkpoint at 49 epochs
2025/05/28 16:13:31 - mmengine - INFO - Epoch(val) [49][10/10]    eta: 0:00:00  time: 0.3475  data_time: 0.0048  memory: 798  
2025/05/28 16:13:31 - mmengine - INFO - Epoch(val) [49][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0048  time: 0.3404
2025/05/28 16:13:40 - mmengine - INFO - Epoch(train) [50][10/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:00:26  time: 0.9642  data_time: 0.0050  memory: 2158  loss: 0.7090  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7090
2025/05/28 16:13:50 - mmengine - INFO - Epoch(train) [50][20/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:00:16  time: 0.9646  data_time: 0.0051  memory: 2158  loss: 0.6816  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6816
2025/05/28 16:14:00 - mmengine - INFO - Epoch(train) [50][30/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:00:06  time: 0.9628  data_time: 0.0036  memory: 2158  loss: 0.6992  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6992
2025/05/28 16:14:06 - mmengine - INFO - Exp name: swin_tiny_raw_20250528_153643
2025/05/28 16:14:06 - mmengine - INFO - Epoch(train) [50][37/37]  base_lr: 2.7391e-06 lr: 2.7391e-07  eta: 0:00:00  time: 0.9642  data_time: 0.0034  memory: 2158  loss: 0.6894  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6894
2025/05/28 16:14:06 - mmengine - INFO - Saving checkpoint at 50 epochs
2025/05/28 16:14:16 - mmengine - INFO - Epoch(val) [50][10/10]    eta: 0:00:00  time: 0.3549  data_time: 0.0048  memory: 798  
2025/05/28 16:14:16 - mmengine - INFO - Epoch(val) [50][10/10]    acc/top1: 0.5526  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0042  time: 0.3383
